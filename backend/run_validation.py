#!/usr/bin/env python3
"""ğŸš€ Script Principal de ValidaciÃ³n
Script principal para ejecutar todas las validaciones y pruebas
del sistema de trading avanzado.

Desarrollado por: Experto en Trading & ProgramaciÃ³n
"""

import sys
import os
import argparse
from datetime import datetime
from typing import Dict, Any

# Agregar el directorio backend al path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from system_validator import SystemValidator

def run_system_validation() -> Dict[str, Any]:
    """ğŸ”§ Ejecuta validaciÃ³n del sistema"""
    print("ğŸ”§ Ejecutando validaciÃ³n del sistema...")
    validator = SystemValidator()
    return validator.run_comprehensive_validation()

def run_unit_tests() -> bool:
    """ğŸ§ª Ejecuta pruebas unitarias"""
    print("\nğŸ§ª Ejecutando pruebas unitarias...")
    
    try:
        # Importar y ejecutar las pruebas
        from tests.test_enhanced_system import run_all_tests
        result = run_all_tests()
        
        # Determinar si las pruebas pasaron
        success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun) * 100
        return success_rate >= 75  # 75% de Ã©xito mÃ­nimo
        
    except ImportError as e:
        print(f"âŒ Error importando pruebas: {e}")
        return False
    except Exception as e:
        print(f"âŒ Error ejecutando pruebas: {e}")
        return False

def run_integration_tests() -> bool:
    """ğŸ”— Ejecuta pruebas de integraciÃ³n bÃ¡sicas"""
    print("\nğŸ”— Ejecutando pruebas de integraciÃ³n...")
    
    try:
        # Test 1: Importar todos los mÃ³dulos principales
        print("  ğŸ“¦ Probando importaciones...")
        from advanced_indicators import AdvancedIndicators
        from trading_engine.enhanced_strategies import ProfessionalRSIStrategy
        from trading_engine.signal_filters import AdvancedSignalFilter
        from backtesting.enhanced_backtester import EnhancedBacktester
        from sentiment_analyzer import SentimentAnalyzer
        print("    âœ… Importaciones exitosas")
        
        # Test 2: Crear instancias bÃ¡sicas
        print("  ğŸ—ï¸  Probando instanciaciÃ³n...")
        indicators = AdvancedIndicators()
        strategy = ProfessionalRSIStrategy()
        signal_filter = AdvancedSignalFilter()
        backtester = EnhancedBacktester()
        sentiment = SentimentAnalyzer()
        print("    âœ… InstanciaciÃ³n exitosa")
        
        # Test 3: Crear datos de prueba y ejecutar anÃ¡lisis bÃ¡sico
        print("  ğŸ“Š Probando anÃ¡lisis bÃ¡sico...")
        import pandas as pd
        import numpy as np
        
        # Crear datos de muestra
        dates = pd.date_range(start='2024-01-01', periods=50, freq='1h')
        np.random.seed(42)
        prices = np.random.normal(50000, 1000, 50)
        
        test_data = pd.DataFrame({
            'open': prices,
            'high': prices * 1.01,
            'low': prices * 0.99,
            'close': prices,
            'volume': np.random.randint(1000, 10000, 50)
        }, index=dates)
        
        # Probar algunos indicadores
        bb_result = indicators.bollinger_bands(test_data)
        vwap_result = indicators.vwap(test_data)
        atr_result = indicators.average_true_range(test_data)
        
        if not all([bb_result, vwap_result, atr_result]):
            print("    âŒ Error en cÃ¡lculo de indicadores")
            return False
        
        print("    âœ… AnÃ¡lisis bÃ¡sico exitoso")
        
        return True
        
    except Exception as e:
        print(f"    âŒ Error en pruebas de integraciÃ³n: {e}")
        return False

def run_performance_benchmark() -> Dict[str, float]:
    """âš¡ Ejecuta benchmark de rendimiento"""
    print("\nâš¡ Ejecutando benchmark de rendimiento...")
    
    import time
    import pandas as pd
    import numpy as np
    
    results = {}
    
    try:
        from advanced_indicators import AdvancedIndicators
        indicators = AdvancedIndicators()
        
        # Crear dataset de prueba
        print("  ğŸ“Š Creando dataset de prueba...")
        dates = pd.date_range(start='2024-01-01', periods=1000, freq='1h')
        np.random.seed(42)
        prices = np.random.normal(50000, 1000, 1000)
        
        test_data = pd.DataFrame({
            'open': prices,
            'high': prices * 1.01,
            'low': prices * 0.99,
            'close': prices,
            'volume': np.random.randint(1000, 10000, 1000).astype('float64')
        }, index=dates)
        
        # Benchmark indicadores individuales
        indicators_to_test = [
            ('Bollinger Bands', lambda: indicators.bollinger_bands(test_data)),
            ('VWAP', lambda: indicators.vwap(test_data)),
            ('OBV', lambda: indicators.on_balance_volume(test_data)),
            ('MFI', lambda: indicators.money_flow_index(test_data)),
            ('ATR', lambda: indicators.average_true_range(test_data)),
            ('Volume Profile', lambda: indicators.volume_profile(test_data)),
            ('Support/Resistance', lambda: indicators.support_resistance_levels(test_data))
        ]
        
        for name, func in indicators_to_test:
            start_time = time.time()
            try:
                func()
                execution_time = time.time() - start_time
                results[name] = execution_time
                print(f"    âœ… {name}: {execution_time:.3f}s")
            except Exception as e:
                print(f"    âŒ {name}: ERROR - {e}")
                results[name] = float('inf')
        
        # Calcular tiempo total
        total_time = sum(t for t in results.values() if t != float('inf'))
        results['Total'] = total_time
        
        print(f"  ğŸ“Š Tiempo total: {total_time:.3f}s")
        
        # Evaluar rendimiento
        if total_time < 2.0:
            print(f"  ğŸ‰ Rendimiento: EXCELENTE")
        elif total_time < 5.0:
            print(f"  âœ… Rendimiento: BUENO")
        elif total_time < 10.0:
            print(f"  âš ï¸  Rendimiento: ACEPTABLE")
        else:
            print(f"  âŒ Rendimiento: LENTO")
        
        return results
        
    except Exception as e:
        print(f"  âŒ Error en benchmark: {e}")
        return {'error': str(e)}

def generate_comprehensive_report(validation_results: Dict, tests_passed: bool, 
                                integration_passed: bool, performance_results: Dict):
    """ğŸ“„ Genera reporte comprehensivo"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"comprehensive_validation_report_{timestamp}.md"
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(f"# ğŸ“Š Reporte Comprehensivo de ValidaciÃ³n\n\n")
        f.write(f"**Fecha:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # Resumen ejecutivo
        f.write(f"## ğŸ¯ Resumen Ejecutivo\n\n")
        
        overall_status = validation_results.get('overall_status', 'UNKNOWN')
        f.write(f"**Estado General:** {overall_status}\n\n")
        
        status_summary = []
        if validation_results.get('overall_status') in ['EXCELLENT', 'GOOD']:
            status_summary.append("âœ… Sistema validado")
        else:
            status_summary.append("âš ï¸ Sistema requiere atenciÃ³n")
            
        if tests_passed:
            status_summary.append("âœ… Pruebas unitarias pasadas")
        else:
            status_summary.append("âŒ Pruebas unitarias fallidas")
            
        if integration_passed:
            status_summary.append("âœ… IntegraciÃ³n funcional")
        else:
            status_summary.append("âŒ Problemas de integraciÃ³n")
        
        f.write(f"**Resumen:** {' | '.join(status_summary)}\n\n")
        
        # Detalles de validaciÃ³n del sistema
        f.write(f"## ğŸ”§ ValidaciÃ³n del Sistema\n\n")
        
        f.write(f"### ğŸ“¦ Dependencias\n\n")
        for pkg, status in validation_results.get('dependencies', {}).items():
            icon = "âœ…" if status else "âŒ"
            f.write(f"- {icon} {pkg}\n")
        
        f.write(f"\n### ğŸ§© MÃ³dulos\n\n")
        for mod, status in validation_results.get('modules', {}).items():
            icon = "âœ…" if status else "âŒ"
            f.write(f"- {icon} {mod}\n")
        
        f.write(f"\n### ğŸ“Š Fuentes de Datos\n\n")
        for src, status in validation_results.get('data_sources', {}).items():
            icon = "âœ…" if status else "âŒ"
            f.write(f"- {icon} {src}\n")
        
        # Resultados de pruebas
        f.write(f"\n## ğŸ§ª Resultados de Pruebas\n\n")
        f.write(f"- **Pruebas Unitarias:** {'âœ… PASADAS' if tests_passed else 'âŒ FALLIDAS'}\n")
        f.write(f"- **Pruebas de IntegraciÃ³n:** {'âœ… PASADAS' if integration_passed else 'âŒ FALLIDAS'}\n")
        
        # Benchmark de rendimiento
        f.write(f"\n## âš¡ Benchmark de Rendimiento\n\n")
        if 'error' not in performance_results:
            f.write(f"| Indicador | Tiempo (s) |\n")
            f.write(f"|-----------|------------|\n")
            for name, time_val in performance_results.items():
                if time_val != float('inf'):
                    f.write(f"| {name} | {time_val:.3f} |\n")
        else:
            f.write(f"âŒ Error en benchmark: {performance_results['error']}\n")
        
        # Recomendaciones
        f.write(f"\n## ğŸ’¡ Recomendaciones\n\n")
        
        recommendations = []
        
        # Basado en validaciÃ³n del sistema
        if validation_results.get('overall_status') not in ['EXCELLENT', 'GOOD']:
            recommendations.append("ğŸ”§ Revisar y corregir problemas de configuraciÃ³n del sistema")
        
        # Basado en pruebas
        if not tests_passed:
            recommendations.append("ğŸ§ª Investigar y corregir fallos en pruebas unitarias")
        
        if not integration_passed:
            recommendations.append("ğŸ”— Resolver problemas de integraciÃ³n entre mÃ³dulos")
        
        # Basado en rendimiento
        total_time = performance_results.get('Total', 0)
        if total_time > 10.0:
            recommendations.append("âš¡ Optimizar rendimiento de indicadores")
        
        if not recommendations:
            f.write(f"ğŸ‰ Â¡No se requieren acciones adicionales! El sistema estÃ¡ funcionando Ã³ptimamente.\n")
        else:
            for i, rec in enumerate(recommendations, 1):
                f.write(f"{i}. {rec}\n")
        
        # PrÃ³ximos pasos
        f.write(f"\n## ğŸš€ PrÃ³ximos Pasos\n\n")
        f.write(f"1. ğŸ“ˆ Ejecutar backtesting con datos reales\n")
        f.write(f"2. ğŸ”„ Configurar monitoreo continuo\n")
        f.write(f"3. ğŸ“Š Implementar dashboard de mÃ©tricas\n")
        f.write(f"4. ğŸ›¡ï¸ Configurar alertas de sistema\n")
        f.write(f"5. ğŸ“ Documentar procedimientos operativos\n")
    
    print(f"\nğŸ“„ Reporte comprehensivo guardado en: {filename}")
    return filename

def main():
    """ğŸš€ FunciÃ³n principal"""
    parser = argparse.ArgumentParser(description='ğŸ”§ Validador Comprehensivo del Sistema de Trading')
    parser.add_argument('--skip-tests', action='store_true', help='Omitir pruebas unitarias')
    parser.add_argument('--skip-integration', action='store_true', help='Omitir pruebas de integraciÃ³n')
    parser.add_argument('--skip-performance', action='store_true', help='Omitir benchmark de rendimiento')
    parser.add_argument('--report-only', action='store_true', help='Solo generar reporte')
    
    args = parser.parse_args()
    
    print(f"{'='*80}")
    print(f"ğŸš€ VALIDADOR COMPREHENSIVO DEL SISTEMA DE TRADING")
    print(f"{'='*80}")
    print(f"â° Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. ValidaciÃ³n del sistema
    validation_results = run_system_validation()
    
    # 2. Pruebas unitarias
    tests_passed = True
    if not args.skip_tests and not args.report_only:
        tests_passed = run_unit_tests()
    elif args.skip_tests:
        print("\nğŸ§ª Pruebas unitarias omitidas")
    
    # 3. Pruebas de integraciÃ³n
    integration_passed = True
    if not args.skip_integration and not args.report_only:
        integration_passed = run_integration_tests()
    elif args.skip_integration:
        print("\nğŸ”— Pruebas de integraciÃ³n omitidas")
    
    # 4. Benchmark de rendimiento
    performance_results = {}
    if not args.skip_performance and not args.report_only:
        performance_results = run_performance_benchmark()
    elif args.skip_performance:
        print("\nâš¡ Benchmark de rendimiento omitido")
    
    # 5. Generar reporte comprehensivo
    report_file = generate_comprehensive_report(
        validation_results, tests_passed, integration_passed, performance_results
    )
    
    # Resumen final
    print(f"\n{'='*80}")
    print(f"ğŸ“Š RESUMEN FINAL")
    print(f"{'='*80}")
    
    overall_success = (
        validation_results.get('overall_status') in ['EXCELLENT', 'GOOD'] and
        tests_passed and
        integration_passed
    )
    
    if overall_success:
        print(f"ğŸ‰ Â¡VALIDACIÃ“N EXITOSA! El sistema estÃ¡ listo para producciÃ³n.")
        exit_code = 0
    else:
        print(f"âš ï¸  VALIDACIÃ“N PARCIAL. Revisar reporte para detalles.")
        exit_code = 1
    
    print(f"ğŸ“„ Reporte detallado: {report_file}")
    print(f"â° Completado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    return exit_code

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)